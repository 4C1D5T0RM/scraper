import requests
from bs4 import BeautifulSoup

def scrape_website(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        output_lines = []

        # Extract header content
        header = soup.find('header')
        if header:
            header_text = header.get_text(separator=' ', strip=True)
            if header_text:
                output_lines.append(f"HEADER: {header_text}")

        # Extract footer content
        footer = soup.find('footer')
        if footer:
            footer_text = footer.get_text(separator=' ', strip=True)
            if footer_text:
                output_lines.append(f"FOOTER: {footer_text}")

        # Extract headings and paragraphs
        elements = soup.find_all(['h1', 'h2', 'h3', 'p'])
        for el in elements:
            tag = el.name.upper()
            text = el.get_text(separator=' ', strip=True)
            if text:
                output_lines.append(f"{tag}: {text}")

        # Show result
        if output_lines:
            print("\nğŸ“„ SCRAPED STRUCTURED TEXT:\n")
            for line in output_lines:
                print(line)

            # Ask if the user wants to save
            save = input("\nğŸ’¾ Do you want to save this content to a .txt file? (yes/no): ").strip().lower()
            if save in ['yes', 'y']:
                filename = input("ğŸ“„ Enter a filename (without extension): ").strip()
                if not filename:
                    filename = "scraped_content"
                with open(f"{filename}.txt", "w", encoding="utf-8") as f:
                    for line in output_lines:
                        f.write(line + "\n")
                print(f"âœ… Content saved as {filename}.txt")
            else:
                print("ğŸ“ Content not saved.")
        else:
            print("âš  No main content found.")

    except requests.exceptions.RequestException as e:
        print(f"âŒ Error fetching the page: {e}")

def main():
    while True:
        url = input("ğŸŒ Enter the URL to scrape (or type 'exit' to quit): ").strip()
        if url.lower() == 'exit':
            print("ğŸ‘‹ Goodbye!")
            break
        if not url.startswith('http'):
            print("âš  Please enter a valid URL (including http/https).")
            continue
        scrape_website(url)

if __name__ == "__main__":
    main()
